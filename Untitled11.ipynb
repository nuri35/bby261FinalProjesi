{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPg+WbJlWHXloZUU063iRDN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nuri35/bby261FinalProjesi/blob/master/Untitled11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsLwf01TQji1",
        "colab_type": "code",
        "outputId": "739adab2-e46c-4c71-cb7d-a29917e0deb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from _future_ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # kutuphaneleri eklıyoruz \n",
        "  # Use the %tensorflow_version magic if in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "import tensorflow as tf\n",
        "# Import TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "# load data ile içindeki veriyi alyoz indirme işlemi baslatıyor\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "#Veri setimizdeki etiketleri  kategorik matriks yapısına çevirmemiz gerekiyor.\n",
        "from keras.utils import to_categorical\n",
        "print('Training data shape : ', train_images.shape, train_labels.shape)\n",
        "print('Testing data shape : ', test_images.shape, test_labels.shape)\n",
        "# Find the unique numbers from the trpy ain labels\n",
        "#essiz sınıf listesi\n",
        "\n",
        "classes = np.unique(train_labels)\n",
        "nClasses = len(classes)\n",
        "print('Total number of outputs : ', nClasses)\n",
        "print('Output classes : ', classes)\n",
        "\n",
        "plt.figure(figsize=[10,5])\n",
        "\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.imshow(train_images[0, :, :], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(train_labels[0]))\n",
        "\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.imshow(test_images[0, :, :], cmap='gray')\n",
        "plt.title(\"Ground Truth : {}\".format(test_labels[0]))\n",
        "plt.show()\n",
        "\n",
        "dimData = np.prod(train_images.shape[1:])\n",
        "train_data = train_images.reshape(train_images.shape[0], dimData)\n",
        "test_data = test_images.reshape(test_images.shape[0], dimData)\n",
        "\n",
        "train_data = train_data.astype('float32')\n",
        "test_data = test_data.astype('float32')\n",
        "\n",
        "train_data /= 255\n",
        "test_data /= 255\n",
        "\n",
        "train_labels_one_hot = to_categorical(train_labels)\n",
        "test_labels_one_hot = to_categorical(test_labels)\n",
        "\n",
        "print('Original label 0 : ', train_labels[0])\n",
        "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[0])\n",
        "#model olusturmak\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10,  activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_data, train_labels_one_hot,batch_size=256, epochs=20, verbose=1,validation_data(test_data,test_labels_one_hot))\n",
        "print(history.history.keys()\n",
        "[test_loss, test_acc] =model.evaluate(test_data,test_labels_one_hot)\n",
        "print(\"Evaluation result on Test Data : [Loss] = , accuracy\".format(test_loss, test_acc))\n",
        "\n",
        "print(\"Test seti \\\"accuracy\\\" değeri {:.2f}\".format(test_acc))\n",
        "# Plot the Loss Curves\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['loss'], 'r')\n",
        "plt.plot(history.history['val_loss'], 'b')\n",
        "plt.legend(['Training loss', 'Validation Loss'])\n",
        "plt.xlabel('Epochs ')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss Curves')\n",
        "\n",
        "# Plot the Accuracy Curves\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['acc'], 'r')\n",
        "plt.plot(history.history['val_acc'], 'b')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
        "plt.xlabel('Epochs ')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy Curves')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "#dropout için yeniden düzenleme\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model_reg = Sequential()\n",
        "model_reg.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model_reg.add(Dropout(0.5))\n",
        "model_reg.add(Dense(512, activation='relu'))\n",
        "model_reg.add(Dropout(0.5))\n",
        "model_reg.add(Dense(nClasses, activation='softmax'))\n",
        "\n",
        "model_reg.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_reg = model_reg.fit(train_data, train_labels_one_hot, batch_size=256, epochs=20, verbose=1,validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "# Plot the Loss Curves\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.plot(history_reg.history['loss'], 'r', linewidth=3.0)\n",
        "plt.plot(history_reg.history['val_loss'], 'b', linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n",
        "plt.xlabel('Epochs ', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "\n",
        "# Plot the Accuracy Curves\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.plot(history_reg.history['acc'], 'r', linewidth=3.0)\n",
        "plt.plot(history_reg.history['val_acc'], 'b', linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
        "plt.xlabel('Epochs ', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "#dropout için yeniden düzenleme\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "model_reg = Sequential()\n",
        "model_reg.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
        "model_reg.add(Dropout(0.5))\n",
        "model_reg.add(Dense(512, activation='relu'))\n",
        "model_reg.add(Dropout(0.5))\n",
        "model_reg.add(Dense(nClasses, activation='softmax'))\n",
        "\n",
        "model_reg.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history_reg = model_reg.fit(train_data, train_labels_one_hot, batch_size=256, epochs=20, verbose=1,validation_data=(test_data, test_labels_one_hot))\n",
        "\n",
        "# Plot the Loss Curves\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.plot(history_reg.history['loss'], 'r', linewidth=3.0)\n",
        "plt.plot(history_reg.history['val_loss'], 'b', linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'], fontsize=18)\n",
        "plt.xlabel('Epochs ', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.title('Loss Curves', fontsize=16)\n",
        "\n",
        "# Plot the Accuracy Curves\n",
        "plt.figure(figsize=[8, 6])\n",
        "plt.plot(history_reg.history['acc'], 'r', linewidth=3.0)\n",
        "plt.plot(history_reg.history['val_acc'], 'b', linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
        "plt.xlabel('Epochs ', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.title('Accuracy Curves', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "model_reg.predict_classes(test_data[[0],:])\n",
        "\n",
        "model_reg.predict(test_data[[0],:])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-7da4a611ade4>\"\u001b[0;36m, line \u001b[0;32m78\u001b[0m\n\u001b[0;31m    print(\"Evaluation result on Test Data : [Loss] = , accuracy\".format(test_loss, test_acc))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ownBirIW_F8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}